import os
import sys
import warnings
from typing import Dict

# è§£å†³OpenMPåº“å†²çª
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
# è¿‡æ»¤è­¦å‘Š
warnings.filterwarnings("ignore")

import time
from multi_stage_generator import MultiStageChatSystem  
from utils import setup_logging, ConfigManager

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    print("æ£€æŸ¥ç¯å¢ƒé…ç½®...")
    
    # æ£€æŸ¥å¿…è¦çš„åº“
    try:
        import torch
        import transformers
        import langchain
        import yaml
        import tqdm
        print(f"âœ… PyTorch: {torch.__version__}")
        print(f"âœ… Transformers: {transformers.__version__}")
        print(f"âœ… LangChain: {langchain.__version__}")
        print(f"âœ… PyYAML: {yaml.__version__}")
        print(f"âœ… TQDM: {tqdm.__version__}")
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„åº“: {e}")
        return False
    
    # æ£€æŸ¥CUDA
    if torch.cuda.is_available():
        print(f"âœ… CUDAå¯ç”¨: {torch.cuda.get_device_name(0)}")
        print(f"âœ… GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
    
    return True

def collect_project_requirements():
    """æ”¶é›†é¡¹ç›®éœ€æ±‚"""
    print("\n" + "=" * 80)
    print("AFSIM å¤šé˜¶æ®µé¡¹ç›®ç”Ÿæˆç³»ç»Ÿ")
    print("=" * 80)
    
    print("\nè¯·è¾“å…¥AFSIMé¡¹ç›®éœ€æ±‚ï¼ˆæ”¯æŒå¤šè¡Œè¾“å…¥ï¼‰ï¼š")
    print("ç¤ºä¾‹ï¼šåˆ›å»ºä¸€ä¸ªæˆ˜æ–—æœºç©ºæˆ˜æ¨¡æ‹Ÿé¡¹ç›®ï¼ŒåŒ…å«F-22å’ŒSU-35å¹³å°")
    print("     é…ç½®é›·è¾¾ã€å¯¼å¼¹ç³»ç»Ÿï¼Œåˆ›å»ºç©ºæˆ˜åœºæ™¯")
    print("     å®ç°é£è¡Œæ§åˆ¶å’Œæˆ˜æœ¯å¤„ç†å™¨")
    print("-" * 80)
    
    requirements = []
    print("å¼€å§‹è¾“å…¥ï¼ˆè¾“å…¥ç©ºè¡Œç»“æŸï¼‰ï¼š")
    
    line_count = 0
    while True:
        try:
            line = input().strip()
            if line == "" and line_count > 0:
                break
            if line:
                requirements.append(line)
                line_count += 1
        except KeyboardInterrupt:
            print("\n\nè¾“å…¥ä¸­æ–­")
            return None
    
    if not requirements:
        print("âŒ éœ€æ±‚ä¸èƒ½ä¸ºç©º")
        return None
    
    return "\n".join(requirements)

def display_generated_project(result, total_time):
    """æ˜¾ç¤ºç”Ÿæˆçš„é¡¹ç›®ç»“æœ"""
    print("\n" + "=" * 80)
    print("ç”Ÿæˆå®Œæˆï¼")
    print("=" * 80)
    
    if result.get("success"):
        print(f"âœ… é¡¹ç›®ç”ŸæˆæˆåŠŸï¼")
        print(f"ğŸ“ é¡¹ç›®ä½ç½®: {result['project_dir']}")
        print(f"ğŸ“„ ç”Ÿæˆæ–‡ä»¶æ•°: {len(result.get('generated_files', []))}")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f}ç§’")
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
        print("\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("-" * 40)
        for i, file_path in enumerate(result.get('generated_files', []), 1):
            print(f"  {i:2d}. {file_path}")
        
        # æ˜¾ç¤ºé˜¶æ®µç»Ÿè®¡
        if result.get("report", {}).get("summary"):
            summary = result["report"]["summary"]
            print(f"\nğŸ“Š é˜¶æ®µç»Ÿè®¡:")
            print(f"   æˆåŠŸé˜¶æ®µ: {summary['successful_stages']}/{summary['total_stages']}")
            print(f"   å¹³å‡é˜¶æ®µè€—æ—¶: {summary['avg_stage_duration']:.1f}ç§’")
        
        print(f"\nğŸ’¡ æç¤º: è¯·æŸ¥çœ‹ {result['project_dir']} æ–‡ä»¶å¤¹è·å–å®Œæ•´é¡¹ç›®ã€‚")
        
        return True
    else:
        print(f"âŒ é¡¹ç›®ç”Ÿæˆå¤±è´¥")
        if result.get("error"):
            print(f"é”™è¯¯: {result['error']}")
        return False

def view_file_content(project_dir, files):
    """æŸ¥çœ‹ç‰¹å®šæ–‡ä»¶çš„å†…å®¹"""
    print("\nå¯æŸ¥çœ‹çš„æ–‡ä»¶:")
    for i, file_path in enumerate(files[:10], 1):
        print(f"  {i:2d}. {file_path}")
    
    try:
        choice = input("\nè¯·è¾“å…¥æ–‡ä»¶ç¼–å·ï¼ˆ0è·³è¿‡ï¼‰: ").strip()
        if choice.isdigit() and 1 <= int(choice) <= len(files):
            file_idx = int(choice) - 1
            file_path = files[file_idx]
            full_path = os.path.join(project_dir, file_path)
            
            if os.path.exists(full_path):
                print(f"\n{'='*60}")
                print(f"æ–‡ä»¶å†…å®¹: {file_path}")
                print('='*60)
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    print(content[:1000])  # åªæ˜¾ç¤ºå‰1000å­—ç¬¦
                    if len(content) > 1000:
                        print(f"\n... (æ–‡ä»¶è¿‡é•¿ï¼Œåªæ˜¾ç¤ºå‰1000å­—ç¬¦)")
                print('='*60)
    except:
        pass

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("AFSIM æ™ºèƒ½ä»£ç ç”Ÿæˆç³»ç»Ÿ (å¤šé˜¶æ®µç”Ÿæˆç‰ˆ)")
    print("=" * 80)
    
    # è®¾ç½®æ—¥å¿—
    setup_logging()
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        print("ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·å®‰è£…å¿…è¦çš„ä¾èµ–åº“")
        return
    
    # åŠ è½½é…ç½®
    config = ConfigManager()
    
    # é…ç½®è·¯å¾„
    project_root = config.get('project.root')
    model_path = config.get('model.path')
    
    if not os.path.exists(project_root):
        print(f"âŒ é”™è¯¯: é¡¹ç›®ç›®å½•ä¸å­˜åœ¨: {project_root}")
        print("è¯·ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ project.root")
        return
    
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_path}")
        print("è¯·ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ model.path")
        return
    
    try:
        # åˆå§‹åŒ–å¤šé˜¶æ®µç”Ÿæˆç³»ç»Ÿ - ç°åœ¨åªéœ€è¦å¯¼å…¥ä¸€ä¸ªç±»
        print("\næ­£åœ¨åˆå§‹åŒ–å¤šé˜¶æ®µç”Ÿæˆç³»ç»Ÿ...")
        chat_system = MultiStageChatSystem(
            project_root=project_root,
            model_path=model_path
        )
        
        print("âœ… å¤šé˜¶æ®µç”Ÿæˆç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
        
        # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
        project_info = chat_system.get_project_info()
        print(f"\nğŸ“Š é¡¹ç›®çŸ¥è¯†åº“ç»Ÿè®¡:")
        print(f"   æ€»æ–‡ä»¶æ•°: {project_info['total_files']}")
        print(f"   åŸºç¡€åº“: {', '.join(project_info['base_libraries'])}")
        print(f"   çŸ¥è¯†åº“: {chat_system.get_vector_db_info()}")
        
        # ä¸»å¾ªç¯ (ä¿æŒä¸å˜)
        while True:
            # æ”¶é›†é¡¹ç›®éœ€æ±‚
            query = collect_project_requirements()
            if query is None:
                continue
            
            # ç¡®è®¤ç”Ÿæˆ
            print(f"\néœ€æ±‚æ‘˜è¦: {query[:100]}...")
            confirm = input("\næ˜¯å¦å¼€å§‹ç”Ÿæˆé¡¹ç›®ï¼Ÿ(y/n): ").strip().lower()
            if confirm != 'y' and confirm != 'yes':
                print("ç”Ÿæˆå–æ¶ˆ")
                continue
            
            # ç”Ÿæˆé¡¹ç›®
            print("\n" + "=" * 80)
            print("å¼€å§‹ç”ŸæˆAFSIMé¡¹ç›®...")
            print("=" * 80)
            
            start_time = time.time()
            result = chat_system.generate_complete_project(query)
            total_time = time.time() - start_time
            
            # æ˜¾ç¤ºç»“æœ
            success = display_generated_project(result, total_time)
            
            # å¦‚æœç”ŸæˆæˆåŠŸï¼Œè¯¢é—®æ˜¯å¦æŸ¥çœ‹æ–‡ä»¶å†…å®¹
            if success:
                view_files = input("\næ˜¯å¦æŸ¥çœ‹æŸä¸ªæ–‡ä»¶çš„å…·ä½“å†…å®¹ï¼Ÿ(y/n): ").strip().lower()
                if view_files == 'y' or view_files == 'yes':
                    view_file_content(result['project_dir'], result.get('generated_files', []))
            
            print("\n" + "=" * 80)
            
            # è¯¢é—®æ˜¯å¦ç»§ç»­
            continue_gen = input("\næ˜¯å¦ç”Ÿæˆå¦ä¸€ä¸ªé¡¹ç›®ï¼Ÿ(y/n): ").strip().lower()
            if continue_gen != 'y' and continue_gen != 'yes':
                print("\næ„Ÿè°¢ä½¿ç”¨ AFSIM æ™ºèƒ½ä»£ç ç”Ÿæˆç³»ç»Ÿï¼å†è§ï¼")
                break
            
    except KeyboardInterrupt:
        print(f"\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        print("æ„Ÿè°¢ä½¿ç”¨ AFSIM æ™ºèƒ½ä»£ç ç”Ÿæˆç³»ç»Ÿï¼å†è§ï¼")
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ç¡®ä¿èµ„æºæ¸…ç†
        if 'chat_system' in locals():
            del chat_system
        # æ¸…ç†GPUå†…å­˜
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        except:
            pass

if __name__ == "__main__":
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    main()