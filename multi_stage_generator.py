# multi_stage_generator.py (æ•´åˆç‰ˆ)
import os
import json
import re
import time
import logging
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from pathlib import Path

@dataclass
class GenerationStage:
    """ç”Ÿæˆé˜¶æ®µå®šä¹‰"""
    name: str
    description: str
    max_tokens: int = 500
    temperature: float = 0.2
    depends_on: List[str] = field(default_factory=list)
    output_patterns: List[str] = field(default_factory=list)

class AFSimProjectStructure:
    """AFSIMé¡¹ç›®ç»“æ„åˆ†æå™¨"""
    
    def __init__(self):
        self.structure_templates = {
            "simple": {
                "files": ["main.txt"],
                "folders": ["platforms", "scenarios"]
            },
            "standard": {
                "files": ["main.txt", "README.md", "input_variables.txt"],
                "folders": ["platforms", "scenarios", "processors", "weapons", "sensors"]
            },
            "complex": {
                "files": ["main.txt", "README.md", "input_variables.txt", 
                         "event_output.txt", "run_me_first.txt"],
                "folders": ["platforms", "scenarios", "processors", 
                           "weapons", "sensors", "patterns", "avionics", "doc"]
            },
            "satellite": {
                "files": ["main.txt", "README.md", "satellite.json"],
                "folders": ["platforms", "scenarios", "TLE", "satellites", 
                           "ground_networks", "avionics"]
            }
        }
    
    def analyze_requirements(self, query: str) -> Dict:
        """åˆ†æéœ€æ±‚ï¼Œç¡®å®šé¡¹ç›®ç»“æ„"""
        query_lower = query.lower()
        
        # æ£€æµ‹é¡¹ç›®ç±»å‹
        project_type = "standard"
        if any(word in query_lower for word in ["å«æ˜Ÿ", "satellite", "è½¨é“", "orbit"]):
            project_type = "satellite"
        elif any(word in query_lower for word in ["é€šä¿¡", "communication", "comm", "ç½‘ç»œ"]):
            project_type = "complex"
        elif any(word in query_lower for word in ["ç®€å•", "simple", "åŸºç¡€", "basic"]):
            project_type = "simple"
        
        # æ£€æµ‹éœ€è¦çš„ç»„ä»¶
        components = self._detect_components(query_lower)
        
        # æ„å»ºé¡¹ç›®ç»“æ„
        structure = self._build_project_structure(project_type, components)
        
        return {
            "project_type": project_type,
            "components": components,
            "structure": structure,
            "stages": self._generate_stages(project_type, components)
        }
    
    def _detect_components(self, query: str) -> Dict[str, bool]:
        """æ£€æµ‹éœ€è¦çš„ç»„ä»¶"""
        return {
            "platforms": any(word in query for word in ["å¹³å°", "platform", "é£æœº", "aircraft", "é£è¡Œå™¨"]),
            "weapons": any(word in query for word in ["æ­¦å™¨", "weapon", "å¯¼å¼¹", "missile", "ç«ç‚®"]),
            "sensors": any(word in query for word in ["ä¼ æ„Ÿå™¨", "sensor", "é›·è¾¾", "radar", "æ¢æµ‹"]),
            "processors": any(word in query for word in ["å¤„ç†å™¨", "processor", "æ§åˆ¶", "control", "ç®—æ³•"]),
            "scenarios": any(word in query for word in ["åœºæ™¯", "scenario", "ä»»åŠ¡", "mission", "æƒ³å®š"]),
            "communications": any(word in query for word in ["é€šä¿¡", "communication", "comm", "ç½‘ç»œ", "network"]),
            "navigation": any(word in query for word in ["å¯¼èˆª", "navigation", "gps", "å®šä½"]),
            "patterns": any(word in query for word in ["æ¨¡å¼", "pattern", "é˜µå‹", "formation"]),
        }
    
    def _build_project_structure(self, project_type: str, components: Dict) -> Dict:
        """æ„å»ºé¡¹ç›®ç»“æ„"""
        base_structure = self.structure_templates.get(project_type, self.structure_templates["standard"])
        
        # æ ¹æ®ç»„ä»¶è°ƒæ•´ç»“æ„
        adjusted_structure = {
            "files": base_structure["files"].copy(),
            "folders": base_structure["folders"].copy()
        }
        
        # æ·»åŠ å¿…è¦çš„æ–‡ä»¶å¤¹
        if components["communications"]:
            if "avionics" not in adjusted_structure["folders"]:
                adjusted_structure["folders"].append("avionics")
            if "ground_networks" not in adjusted_structure["folders"]:
                adjusted_structure["folders"].append("ground_networks")
        
        if components["navigation"]:
            if "TLE" not in adjusted_structure["folders"]:
                adjusted_structure["folders"].append("TLE")
            if "satellites" not in adjusted_structure["folders"]:
                adjusted_structure["folders"].append("satellites")
        
        return adjusted_structure
    
    def _generate_stages(self, project_type: str, components: Dict) -> List[Dict]:
        """ç”Ÿæˆé˜¶æ®µè®¡åˆ’"""
        stages = [
            {
                "name": "project_structure",
                "description": "åˆ†æéœ€æ±‚å¹¶è§„åˆ’é¡¹ç›®ç»“æ„",
                "depends_on": [],
                "output_patterns": ["project_structure.json"]
            },
            {
                "name": "main_program",
                "description": "ç”Ÿæˆä¸»ç¨‹åºæ–‡ä»¶",
                "depends_on": ["project_structure"],
                "output_patterns": ["main.txt"]
            }
        ]
        
        # æ ¹æ®ç»„ä»¶æ·»åŠ é˜¶æ®µ
        if components["platforms"]:
            stages.append({
                "name": "platforms",
                "description": "ç”Ÿæˆå¹³å°å®šä¹‰æ–‡ä»¶",
                "depends_on": ["project_structure"],
                "output_patterns": ["platforms/*.txt"]
            })
        
        if components["scenarios"]:
            stages.append({
                "name": "scenarios",
                "description": "ç”Ÿæˆåœºæ™¯æ–‡ä»¶",
                "depends_on": ["platforms", "main_program"],
                "output_patterns": ["scenarios/*.txt"]
            })
        
        if components["processors"]:
            stages.append({
                "name": "processors",
                "description": "ç”Ÿæˆå¤„ç†å™¨æ–‡ä»¶",
                "depends_on": ["platforms"],
                "output_patterns": ["processors/*.txt"]
            })
        
        if components["sensors"]:
            stages.append({
                "name": "sensors",
                "description": "ç”Ÿæˆä¼ æ„Ÿå™¨æ–‡ä»¶",
                "depends_on": ["platforms"],
                "output_patterns": ["sensors/*.txt"]
            })
        
        if components["weapons"]:
            stages.append({
                "name": "weapons",
                "description": "ç”Ÿæˆæ­¦å™¨æ–‡ä»¶",
                "depends_on": ["platforms"],
                "output_patterns": ["weapons/*.txt"]
            })
        
        # å«æ˜Ÿé¡¹ç›®ç‰¹æ®Šé˜¶æ®µ
        if project_type == "satellite":
            stages.extend([
                {
                    "name": "satellites",
                    "description": "ç”Ÿæˆå«æ˜Ÿè½¨é“æ–‡ä»¶",
                    "depends_on": ["platforms"],
                    "output_patterns": ["satellites/**/*.txt", "TLE/*.txt"]
                },
                {
                    "name": "ground_networks",
                    "description": "ç”Ÿæˆåœ°é¢ç«™ç½‘ç»œæ–‡ä»¶",
                    "depends_on": ["platforms"],
                    "output_patterns": ["ground_networks/*.txt"]
                },
                {
                    "name": "avionics",
                    "description": "ç”Ÿæˆèˆªç”µç³»ç»Ÿæ–‡ä»¶",
                    "depends_on": ["platforms"],
                    "output_patterns": ["avionics/**/*.txt"]
                }
            ])
        
        # é›†æˆé˜¶æ®µ
        stages.append({
            "name": "integration",
            "description": "æ•´åˆå’ŒéªŒè¯æ‰€æœ‰æ–‡ä»¶",
            "depends_on": [stage["name"] for stage in stages[1:] if stage["name"] != "integration"],
            "output_patterns": ["README.md", "run_instructions.txt"]
        })
        
        return stages

class MultiStageGenerator:
    """å¤šé˜¶æ®µç”Ÿæˆå™¨"""
    
    def __init__(self, chat_system, config):
        self.chat_system = chat_system
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.project_analyzer = AFSimProjectStructure()
        
        # é¡¹ç›®çŠ¶æ€
        self.current_project = None
        self.generated_files = []
        self.current_stage = None
        self.project_context = {}
        self.stage_results = {}
        
    def generate_project(self, query: str, output_dir: str = None) -> Dict:
        """ç”Ÿæˆå®Œæ•´çš„AFSIMé¡¹ç›®"""
        try:
            # 1. åˆ†æéœ€æ±‚
            self.logger.info("åˆ†æé¡¹ç›®éœ€æ±‚...")
            print("ğŸ” åˆ†æé¡¹ç›®éœ€æ±‚...")
            project_analysis = self.project_analyzer.analyze_requirements(query)
            
            # 2. å‡†å¤‡è¾“å‡ºç›®å½•
            if not output_dir:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                output_dir = os.path.join(
                    self.config.get('generation.output.base_dir', 'generated_projects'),
                    f"afsim_project_{timestamp}"
                )
            
            os.makedirs(output_dir, exist_ok=True)
            
            # 3. ä¿å­˜é¡¹ç›®åˆ†æ
            self.current_project = {
                "analysis": project_analysis,
                "output_dir": output_dir,
                "query": query,
                "start_time": time.time(),
                "stages": {}
            }
            
            # åˆ›å»ºé¡¹ç›®ç»“æ„
            self._create_project_structure(output_dir, project_analysis["structure"])
            
            # 4. æŒ‰é˜¶æ®µç”Ÿæˆ
            stages = project_analysis["stages"]
            total_stages = len(stages)
            
            for idx, stage_info in enumerate(stages, 1):
                stage_name = stage_info["name"]
                stage_desc = stage_info["description"]
                
                self.current_stage = stage_name
                self.logger.info(f"å¼€å§‹é˜¶æ®µ {idx}/{total_stages}: {stage_name} - {stage_desc}")
                print(f"\nğŸ“‹ é˜¶æ®µ {idx}/{total_stages}: {stage_desc}")
                
                # æ£€æŸ¥ä¾èµ–
                if not self._check_stage_dependencies(stage_info):
                    self.logger.warning(f"é˜¶æ®µ {stage_name} çš„ä¾èµ–æœªæ»¡è¶³ï¼Œè·³è¿‡")
                    print(f"âš ï¸  è·³è¿‡é˜¶æ®µ {stage_name}ï¼ˆä¾èµ–æœªæ»¡è¶³ï¼‰")
                    continue
                
                # æ‰§è¡Œé˜¶æ®µç”Ÿæˆ
                stage_start = time.time()
                result = self._execute_stage(stage_info, query, output_dir)
                stage_duration = time.time() - stage_start
                
                # è®°å½•ç»“æœ
                self.current_project["stages"][stage_name] = {
                    "status": "success" if result["success"] else "failed",
                    "output_files": result.get("output_files", []),
                    "error": result.get("error"),
                    "duration": stage_duration
                }
                
                if result["success"]:
                    self.generated_files.extend(result["output_files"])
                    self.project_context.update(result.get("context", {}))
                    self.stage_results[stage_name] = result
                    print(f"âœ… é˜¶æ®µ {stage_name} å®Œæˆ ({stage_duration:.1f}ç§’)")
                else:
                    self.logger.error(f"é˜¶æ®µ {stage_name} å¤±è´¥: {result.get('error')}")
                    print(f"âŒ é˜¶æ®µ {stage_name} å¤±è´¥: {result.get('error')}")
                
                # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
                if result.get("output_files"):
                    print(f"   ç”Ÿæˆæ–‡ä»¶: {', '.join(result['output_files'])}")
            
            # 5. ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š
            report = self._generate_project_report()
            
            self.logger.info(f"é¡¹ç›®ç”Ÿæˆå®Œæˆ: {output_dir}")
            print(f"\nğŸ‰ é¡¹ç›®ç”Ÿæˆå®Œæˆï¼ä½ç½®: {output_dir}")
            
            return {
                "success": True,
                "project_dir": output_dir,
                "generated_files": self.generated_files,
                "report": report,
                "project_analysis": project_analysis
            }
            
        except Exception as e:
            self.logger.error(f"é¡¹ç›®ç”Ÿæˆå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _create_project_structure(self, output_dir: str, structure: Dict):
        """åˆ›å»ºé¡¹ç›®æ–‡ä»¶å¤¹ç»“æ„"""
        self.logger.info(f"åˆ›å»ºé¡¹ç›®ç»“æ„: {output_dir}")
        
        # åˆ›å»ºæ–‡ä»¶å¤¹
        for folder in structure.get("folders", []):
            folder_path = os.path.join(output_dir, folder)
            os.makedirs(folder_path, exist_ok=True)
            self.logger.debug(f"åˆ›å»ºæ–‡ä»¶å¤¹: {folder_path}")
    
    def _check_stage_dependencies(self, stage_info: Dict) -> bool:
        """æ£€æŸ¥é˜¶æ®µä¾èµ–æ˜¯å¦æ»¡è¶³"""
        depends_on = stage_info.get("depends_on", [])
        if not depends_on:
            return True
        
        for dep in depends_on:
            if dep not in self.current_project["stages"]:
                return False
            if self.current_project["stages"][dep]["status"] != "success":
                return False
        
        return True
    
    def _execute_stage(self, stage_info: Dict, query: str, output_dir: str) -> Dict:
        """æ‰§è¡Œå•ä¸ªç”Ÿæˆé˜¶æ®µ"""
        stage_name = stage_info["name"]
        
        try:
            # æ„å»ºé˜¶æ®µç‰¹å®šçš„æç¤ºè¯
            prompt = self._build_stage_prompt(stage_info, query)
            
            # ç”Ÿæˆå†…å®¹
            result = self.chat_system.generate_enhanced_response(prompt)
            
            if not result or "result" not in result:
                return {
                    "success": False,
                    "error": "ç”Ÿæˆç»“æœä¸ºç©º"
                }
            
            # è§£æç”Ÿæˆçš„å†…å®¹
            generated_content = result["result"]
            
            # æå–æ–‡ä»¶å†…å®¹
            files = self._extract_files_from_content(generated_content, stage_info, output_dir)
            
            # ä¿å­˜æ–‡ä»¶
            output_files = self._save_generated_files(files, output_dir)
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            context = self._extract_context_from_content(generated_content)
            
            return {
                "success": True,
                "output_files": output_files,
                "context": context,
                "raw_content": generated_content,
                "stage_name": stage_name
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def _build_stage_prompt(self, stage_info: Dict, query: str) -> str:
        """æ„å»ºé˜¶æ®µç‰¹å®šçš„æç¤ºè¯"""
        stage_name = stage_info["name"]
        stage_desc = stage_info["description"]
        
        # é˜¶æ®µç‰¹å®šçš„æŒ‡ä»¤
        stage_instructions = {
            "project_structure": f"""è¯·åˆ†æAFSIMé¡¹ç›®éœ€æ±‚å¹¶è§„åˆ’é¡¹ç›®ç»“æ„ã€‚

åŸå§‹éœ€æ±‚ï¼š{query}

è¯·è¾“å‡ºä¸€ä¸ªJSONæ ¼å¼çš„é¡¹ç›®ç»“æ„è§„åˆ’ï¼ŒåŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
1. é¡¹ç›®ç±»å‹ï¼ˆsimple/standard/complex/satelliteï¼‰
2. éœ€è¦çš„ç»„ä»¶åˆ—è¡¨
3. å»ºè®®çš„æ–‡ä»¶ç»“æ„
4. ä¸»è¦å¹³å°åç§°
5. ä¸»è¦åœºæ™¯æè¿°

è¯·åªè¾“å‡ºJSONæ ¼å¼ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚""",
            
            "main_program": f"""è¯·ç”ŸæˆAFSIMä¸»ç¨‹åºæ–‡ä»¶ï¼ˆmain.txtï¼‰ã€‚

åŸºäºä»¥ä¸‹é¡¹ç›®éœ€æ±‚ï¼š{query}

é¡¹ç›®ä¸Šä¸‹æ–‡ï¼š{json.dumps(self.project_context, ensure_ascii=False)}

å·²ç”Ÿæˆçš„æ–‡ä»¶ï¼š{chr(10).join(f"- {f}" for f in self.generated_files)}

ä¸»ç¨‹åºå¿…é¡»åŒ…å«ï¼š
1. å¿…è¦çš„å¯¼å…¥è¯­å¥ï¼ˆä½¿ç”¨includeè¯­å¥ï¼‰
2. å…¨å±€å˜é‡å’Œå¸¸é‡å®šä¹‰
3. åœºæ™¯åˆå§‹åŒ–å’Œè®¾ç½®
4. ä¸»äº‹ä»¶å¾ªç¯
5. è¾“å‡ºé…ç½®
6. ä»¿çœŸæ§åˆ¶å‚æ•°

è¯·ç”Ÿæˆå®Œæ•´çš„main.txtæ–‡ä»¶å†…å®¹ï¼š""",
            
            "platforms": f"""è¯·ç”ŸæˆAFSIMå¹³å°å®šä¹‰æ–‡ä»¶ã€‚

åŸºäºé¡¹ç›®éœ€æ±‚ï¼š{query}

é¡¹ç›®ä¸Šä¸‹æ–‡ï¼š{json.dumps(self.project_context, ensure_ascii=False)}

éœ€è¦ç”Ÿæˆä»¥ä¸‹å¹³å°çš„å®šä¹‰ï¼š
{self._get_platform_requirements()}

æ¯ä¸ªå¹³å°æ–‡ä»¶åº”è¯¥åŒ…å«ï¼š
1. å¹³å°ç±»å‹å®šä¹‰ï¼ˆplatform_typeï¼‰
2. ç‰©ç†å‚æ•°ï¼ˆå°ºå¯¸ã€é‡é‡ã€åŠ¨åŠ›ç­‰ï¼‰
3. åˆå§‹çŠ¶æ€ï¼ˆä½ç½®ã€é€Ÿåº¦ã€æ–¹å‘ï¼‰
4. ç»„ä»¶é…ç½®ï¼ˆä¼ æ„Ÿå™¨ã€æ­¦å™¨ã€å¤„ç†å™¨ç­‰ï¼‰
5. è¡Œä¸ºå®šä¹‰

è¯·ä¸ºæ¯ä¸ªå¹³å°ç”Ÿæˆå•ç‹¬çš„.txtæ–‡ä»¶ã€‚
ä½¿ç”¨ä»¥ä¸‹æ ¼å¼åˆ†éš”ä¸åŒæ–‡ä»¶ï¼š
=== å¹³å°åç§°.txt ===
[å¹³å°æ–‡ä»¶å†…å®¹]
=== å¦ä¸€ä¸ªå¹³å°.txt ===
[å¦ä¸€ä¸ªå¹³å°æ–‡ä»¶å†…å®¹]

è¯·å¼€å§‹ç”Ÿæˆï¼š""",
            
            "scenarios": f"""è¯·ç”ŸæˆAFSIMåœºæ™¯æ–‡ä»¶ã€‚

åŸºäºé¡¹ç›®éœ€æ±‚ï¼š{query}
å·²ç”Ÿæˆçš„å¹³å°ï¼š{json.dumps(self.project_context.get('platforms', []), ensure_ascii=False)}

éœ€è¦åˆ›å»ºä»¥ä¸‹åœºæ™¯ï¼š
1. ä¸»æµ‹è¯•åœºæ™¯
2. è®­ç»ƒåœºæ™¯
3. éªŒè¯åœºæ™¯

æ¯ä¸ªåœºæ™¯æ–‡ä»¶åº”è¯¥åŒ…å«ï¼š
1. åœºæ™¯åç§°å’Œæè¿°
2. å‚ä¸å¹³å°åŠå…¶åˆå§‹é…ç½®
3. ç¯å¢ƒè®¾ç½®ï¼ˆåœ°å½¢ã€å¤©æ°”ã€æ—¶é—´ï¼‰
4. ä»»åŠ¡ç›®æ ‡å’Œçº¦æŸ
5. äº‹ä»¶åºåˆ—å’Œè§¦å‘å™¨

è¯·ä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆå•ç‹¬çš„.txtæ–‡ä»¶ã€‚
ä½¿ç”¨ä»¥ä¸‹æ ¼å¼åˆ†éš”ä¸åŒæ–‡ä»¶ï¼š
=== åœºæ™¯åç§°.txt ===
[åœºæ™¯æ–‡ä»¶å†…å®¹]

è¯·å¼€å§‹ç”Ÿæˆï¼š""",
            
            "processors": f"""è¯·ç”ŸæˆAFSIMå¤„ç†å™¨æ–‡ä»¶ã€‚

åŸºäºé¡¹ç›®éœ€æ±‚ï¼š{query}
å·²ç”Ÿæˆçš„å¹³å°ï¼š{json.dumps(self.project_context.get('platforms', []), ensure_ascii=False)}

éœ€è¦ç”Ÿæˆä»¥ä¸‹å¤„ç†å™¨ï¼š
1. æˆ˜æœ¯å†³ç­–å¤„ç†å™¨
2. ä¼ æ„Ÿå™¨æ•°æ®å¤„ç†å¤„ç†å™¨
3. æ­¦å™¨æ§åˆ¶å¤„ç†å™¨
4. é€šä¿¡å¤„ç†å™¨

æ¯ä¸ªå¤„ç†å™¨æ–‡ä»¶åº”è¯¥åŒ…å«ï¼š
1. å¤„ç†å™¨ç±»å‹å®šä¹‰
2. è¾“å…¥è¾“å‡ºæ¥å£
3. å¤„ç†ç®—æ³•å’Œé€»è¾‘
4. é…ç½®å‚æ•°
5. æ€§èƒ½æŒ‡æ ‡

è¯·ä¸ºæ¯ä¸ªå¤„ç†å™¨ç”Ÿæˆå•ç‹¬çš„.txtæ–‡ä»¶ã€‚
ä½¿ç”¨ä»¥ä¸‹æ ¼å¼åˆ†éš”ä¸åŒæ–‡ä»¶ï¼š
=== å¤„ç†å™¨åç§°.txt ===
[å¤„ç†å™¨æ–‡ä»¶å†…å®¹]

è¯·å¼€å§‹ç”Ÿæˆï¼š""",
            
            "sensors": f"""è¯·ç”ŸæˆAFSIMä¼ æ„Ÿå™¨æ–‡ä»¶ã€‚

åŸºäºé¡¹ç›®éœ€æ±‚ï¼š{query}
å·²ç”Ÿæˆçš„å¹³å°ï¼š{json.dumps(self.project_context.get('platforms', []), ensure_ascii=False)}

éœ€è¦ç”Ÿæˆä»¥ä¸‹ä¼ æ„Ÿå™¨ï¼š
1. é›·è¾¾ä¼ æ„Ÿå™¨
2. å…‰ç”µä¼ æ„Ÿå™¨
3. ç”µå­æ”¯æ´æªæ–½ï¼ˆESMï¼‰
4. é€šä¿¡ä¼ æ„Ÿå™¨

æ¯ä¸ªä¼ æ„Ÿå™¨æ–‡ä»¶åº”è¯¥åŒ…å«ï¼š
1. ä¼ æ„Ÿå™¨ç±»å‹å®šä¹‰
2. æ¢æµ‹å‚æ•°ï¼ˆèŒƒå›´ã€ç²¾åº¦ã€åˆ†è¾¨ç‡ï¼‰
3. å·¥ä½œæ¨¡å¼
4. æ•°æ®è¾“å‡ºæ ¼å¼
5. åŠŸè€—å’Œæ€§èƒ½

è¯·ä¸ºæ¯ä¸ªä¼ æ„Ÿå™¨ç”Ÿæˆå•ç‹¬çš„.txtæ–‡ä»¶ã€‚
ä½¿ç”¨ä»¥ä¸‹æ ¼å¼åˆ†éš”ä¸åŒæ–‡ä»¶ï¼š
=== ä¼ æ„Ÿå™¨åç§°.txt ===
[ä¼ æ„Ÿå™¨æ–‡ä»¶å†…å®¹]

è¯·å¼€å§‹ç”Ÿæˆï¼š""",
            
            "weapons": f"""è¯·ç”ŸæˆAFSIMæ­¦å™¨æ–‡ä»¶ã€‚

åŸºäºé¡¹ç›®éœ€æ±‚ï¼š{query}
å·²ç”Ÿæˆçš„å¹³å°ï¼š{json.dumps(self.project_context.get('platforms', []), ensure_ascii=False)}

éœ€è¦ç”Ÿæˆä»¥ä¸‹æ­¦å™¨ï¼š
1. ç©ºå¯¹ç©ºå¯¼å¼¹
2. ç©ºå¯¹åœ°å¯¼å¼¹
3. æœºç‚®ç³»ç»Ÿ
4. ç‚¸å¼¹

æ¯ä¸ªæ­¦å™¨æ–‡ä»¶åº”è¯¥åŒ…å«ï¼š
1. æ­¦å™¨ç±»å‹å®šä¹‰
2. æ€§èƒ½å‚æ•°ï¼ˆå°„ç¨‹ã€é€Ÿåº¦ã€ç²¾åº¦ï¼‰
3. åˆ¶å¯¼ç³»ç»Ÿ
4. æˆ˜æ–—éƒ¨é…ç½®
5. å‘å°„æ§åˆ¶

è¯·ä¸ºæ¯ä¸ªæ­¦å™¨ç”Ÿæˆå•ç‹¬çš„.txtæ–‡ä»¶ã€‚
ä½¿ç”¨ä»¥ä¸‹æ ¼å¼åˆ†éš”ä¸åŒæ–‡ä»¶ï¼š
=== æ­¦å™¨åç§°.txt ===
[æ­¦å™¨æ–‡ä»¶å†…å®¹]

è¯·å¼€å§‹ç”Ÿæˆï¼š""",
            
            "integration": f"""è¯·æ•´åˆæ‰€æœ‰ç”Ÿæˆçš„AFSIMæ–‡ä»¶ï¼Œåˆ›å»ºé¡¹ç›®æ–‡æ¡£ã€‚

é¡¹ç›®éœ€æ±‚ï¼š{query}

å·²ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨ï¼š
{chr(10).join(f"- {f}" for f in self.generated_files)}

éœ€è¦ç”Ÿæˆï¼š
1. README.md - é¡¹ç›®è¯´æ˜æ–‡æ¡£
2. run_instructions.txt - è¿è¡Œè¯´æ˜

README.mdåº”è¯¥åŒ…å«ï¼š
1. é¡¹ç›®æ¦‚è¿°
2. æ–‡ä»¶ç»“æ„è¯´æ˜
3. å¹³å°å’Œç»„ä»¶ä»‹ç»
4. è¿è¡Œæ–¹æ³•
5. é…ç½®è¯´æ˜

run_instructions.txtåº”è¯¥åŒ…å«ï¼š
1. è¿è¡Œæ­¥éª¤
2. å‚æ•°é…ç½®
3. é¢„æœŸè¾“å‡º
4. æ•…éšœæ’é™¤

è¯·ç”Ÿæˆå®Œæ•´çš„æ–‡æ¡£å†…å®¹ã€‚"""
        }
        
        instruction = stage_instructions.get(stage_name, f"è¯·æ ¹æ®éœ€æ±‚ç”Ÿæˆ{stage_desc}ã€‚")
        return instruction
    
    def _get_platform_requirements(self) -> str:
        """è·å–å¹³å°éœ€æ±‚æè¿°"""
        if "platforms" in self.project_context:
            platforms = self.project_context["platforms"]
            return "\n".join([f"- {p}" for p in platforms])
        return "æ ¹æ®é¡¹ç›®éœ€æ±‚ç”Ÿæˆåˆé€‚çš„å¹³å°"
    
    def _extract_files_from_content(self, content: str, stage_info: Dict, output_dir: str) -> List[Dict]:
        """ä»ç”Ÿæˆçš„å†…å®¹ä¸­æå–æ–‡ä»¶"""
        files = []
        stage_name = stage_info["name"]
        
        if stage_name == "project_structure":
            # å°è¯•è§£æJSON
            try:
                # æå–JSONéƒ¨åˆ†
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    json_str = json_match.group()
                    # ä¿å­˜JSONæ–‡ä»¶
                    files.append({
                        "path": "project_structure.json",
                        "content": json.dumps(json.loads(json_str), indent=2, ensure_ascii=False)
                    })
                    
                    # è§£æå¹¶æ›´æ–°ä¸Šä¸‹æ–‡
                    structure_data = json.loads(json_str)
                    if "platforms" in structure_data:
                        self.project_context["platforms"] = structure_data.get("platforms", [])
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯JSONï¼Œä¿å­˜ä¸ºæ–‡æœ¬
                files.append({
                    "path": "project_structure.txt",
                    "content": content
                })
                
        elif stage_name == "main_program":
            files.append({
                "path": "main.txt",
                "content": content
            })
            
        elif stage_name in ["platforms", "scenarios", "processors", "sensors", "weapons", 
                           "satellites", "ground_networks", "avionics"]:
            # ä½¿ç”¨æ™ºèƒ½æ–‡ä»¶åˆ†å‰²
            files.extend(self._extract_multiple_files_smart(content, stage_name))
            
        elif stage_name == "integration":
            # å¤„ç†é›†æˆæ–‡æ¡£
            files.extend(self._extract_integration_files(content))
        
        return files
    
    def _extract_multiple_files_smart(self, content: str, folder_name: str) -> List[Dict]:
        """æ™ºèƒ½æå–å¤šä¸ªæ–‡ä»¶"""
        files = []
        
        # å¤šç§æ–‡ä»¶åˆ†éš”æ¨¡å¼
        patterns = [
            (r'=== (.+?\.txt) ===\n(.*?)(?=\n=== |\Z)', re.DOTALL),  # === æ–‡ä»¶å.txt ===
            (r'// File: (.+?\.txt)\n(.*?)(?=\n// File: |\Z)', re.DOTALL),  # // File: æ–‡ä»¶å.txt
            (r'# File: (.+?\.txt)\n(.*?)(?=\n# File: |\Z)', re.DOTALL),  # # File: æ–‡ä»¶å.txt
            (r'æ–‡ä»¶ï¼š(.+?\.txt)\n(.*?)(?=\næ–‡ä»¶ï¼š|\Z)', re.DOTALL),  # æ–‡ä»¶ï¼šæ–‡ä»¶å.txt
            (r'(\w+)_platform\.txt:\n(.*?)(?=\n\w+_platform\.txt:|\Z)', re.DOTALL),  # å¹³å°å_platform.txt:
        ]
        
        for pattern, flags in patterns:
            matches = re.findall(pattern, content, flags)
            if matches:
                for filename, file_content in matches:
                    # æ¸…ç†æ–‡ä»¶å
                    filename = filename.strip()
                    if not filename.endswith('.txt'):
                        filename += '.txt'
                    
                    # æ¸…ç†æ–‡ä»¶å†…å®¹
                    file_content = file_content.strip()
                    
                    files.append({
                        "path": f"{folder_name}/{filename}",
                        "content": file_content
                    })
                break
        
        # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„åˆ†å‰²ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        if not files:
            files = self._extract_files_by_platform_pattern(content, folder_name)
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤æ–‡ä»¶
        if not files and content.strip():
            default_name = f"{folder_name}_main.txt"
            files.append({
                "path": f"{folder_name}/{default_name}",
                "content": content.strip()
            })
        
        return files
    
    def _extract_files_by_platform_pattern(self, content: str, folder_name: str) -> List[Dict]:
        """æ ¹æ®å¹³å°æ¨¡å¼æå–æ–‡ä»¶"""
        files = []
        
        # æŸ¥æ‰¾å¹³å°å®šä¹‰
        platform_patterns = [
            r'platform_type\s+(\w+)',
            r'class\s+(\w+)\s*\{',
            r'(\w+)_platform\s*\{'
        ]
        
        all_platforms = []
        for pattern in platform_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            all_platforms.extend(matches)
        
        # ä¸ºæ¯ä¸ªå¹³å°æå–ç›¸å…³å†…å®¹
        for platform in set(all_platforms):
            # æŸ¥æ‰¾è¯¥å¹³å°çš„ç›¸å…³å†…å®¹
            platform_content = self._extract_platform_content(content, platform)
            if platform_content:
                filename = f"{platform}.txt"
                files.append({
                    "path": f"{folder_name}/{filename}",
                    "content": platform_content
                })
        
        return files
    
    def _extract_platform_content(self, content: str, platform: str) -> str:
        """æå–ç‰¹å®šå¹³å°çš„å†…å®¹"""
        # æŸ¥æ‰¾ä»¥å¹³å°åå¼€å§‹çš„éƒ¨åˆ†
        patterns = [
            fr'platform_type\s+{platform}.*?\n}}(?=\n|$)',
            fr'class\s+{platform}.*?\n}}(?=\n|$)',
            fr'{platform}_platform.*?\n}}(?=\n|$)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if match:
                return match.group().strip()
        
        return ""
    
    def _extract_integration_files(self, content: str) -> List[Dict]:
        """æå–é›†æˆæ–‡ä»¶"""
        files = []
        
        # å°è¯•åˆ†ç¦»READMEå’Œè¿è¡Œè¯´æ˜
        readme_patterns = [
            r'# README\.md.*?\n(.*?)(?=# run_instructions\.txt|# è¿è¡Œè¯´æ˜|\Z)',
            r'README.*?\n(.*?)(?=è¿è¡Œè¯´æ˜|\Z)',
        ]
        
        run_instructions_patterns = [
            r'# run_instructions\.txt.*?\n(.*?)(?=# |\Z)',
            r'è¿è¡Œè¯´æ˜.*?\n(.*?)(?=\Z)',
        ]
        
        readme_content = ""
        run_instructions_content = ""
        
        for pattern in readme_patterns:
            match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if match:
                readme_content = match.group(1).strip()
                break
        
        for pattern in run_instructions_patterns:
            match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if match:
                run_instructions_content = match.group(1).strip()
                break
        
        if not readme_content and not run_instructions_content:
            # å¦‚æœæ— æ³•åˆ†ç¦»ï¼Œæ•´ä¸ªå†…å®¹ä½œä¸ºREADME
            files.append({
                "path": "README.md",
                "content": content
            })
        else:
            if readme_content:
                files.append({
                    "path": "README.md",
                    "content": readme_content
                })
            if run_instructions_content:
                files.append({
                    "path": "run_instructions.txt",
                    "content": run_instructions_content
                })
        
        return files
    
    def _save_generated_files(self, files: List[Dict], output_dir: str) -> List[str]:
        """ä¿å­˜ç”Ÿæˆçš„æ–‡ä»¶"""
        saved_files = []
        
        for file_info in files:
            try:
                file_path = os.path.join(output_dir, file_info["path"])
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                
                # ä¿å­˜æ–‡ä»¶
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(file_info["content"])
                
                saved_files.append(file_info["path"])
                self.logger.debug(f"ä¿å­˜æ–‡ä»¶: {file_info['path']}")
                
            except Exception as e:
                self.logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {file_info['path']}: {e}")
        
        return saved_files
    
    def _extract_context_from_content(self, content: str) -> Dict:
        """ä»å†…å®¹ä¸­æå–ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context = {}
        
        # æå–å¹³å°åç§°
        platform_matches = re.findall(r'platform_type\s+(\w+)', content, re.IGNORECASE)
        if platform_matches:
            context["platforms"] = list(set(platform_matches))
        
        # æå–æ­¦å™¨åç§°
        weapon_matches = re.findall(r'weapon_type\s+(\w+)', content, re.IGNORECASE)
        if weapon_matches:
            context["weapons"] = list(set(weapon_matches))
        
        # æå–ä¼ æ„Ÿå™¨åç§°
        sensor_matches = re.findall(r'sensor_type\s+(\w+)', content, re.IGNORECASE)
        if sensor_matches:
            context["sensors"] = list(set(sensor_matches))
        
        # æå–åœºæ™¯åç§°
        scenario_matches = re.findall(r'scenario\s+(\w+)', content, re.IGNORECASE)
        if scenario_matches:
            context["scenarios"] = list(set(scenario_matches))
        
        return context
    
    def _generate_project_report(self) -> Dict:
        """ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š"""
        if not self.current_project:
            return {}
        
        total_duration = time.time() - self.current_project["start_time"]
        
        return {
            "project_info": {
                "output_dir": self.current_project["output_dir"],
                "query": self.current_project["query"],
                "total_duration": total_duration,
                "generated_files_count": len(self.generated_files)
            },
            "analysis": self.current_project["analysis"],
            "stage_results": self.current_project["stages"],
            "file_list": self.generated_files,
            "summary": {
                "total_stages": len(self.current_project["stages"]),
                "successful_stages": sum(1 for s in self.current_project["stages"].values() 
                                       if s["status"] == "success"),
                "total_files": len(self.generated_files),
                "avg_stage_duration": total_duration / max(len(self.current_project["stages"]), 1)
            }
        }


class MultiStageChatSystem:
    """æ”¯æŒå¤šé˜¶æ®µç”Ÿæˆçš„èŠå¤©ç³»ç»Ÿ"""
    
    def __init__(self, project_root: str, model_path: str = None):
        from rag_enhanced import EnhancedRAGChatSystem
        from utils import setup_logging, ConfigManager
        
        # è®¾ç½®æ—¥å¿—
        setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–åŸºç¡€RAGç³»ç»Ÿ
        self.chat_system = EnhancedRAGChatSystem(
            project_root=project_root,
            model_path=model_path
        )
        
        # åŠ è½½é…ç½®
        self.config = ConfigManager()
        
        # åˆå§‹åŒ–å¤šé˜¶æ®µç”Ÿæˆå™¨
        self.project_analyzer = AFSimProjectStructure()
        self.multi_stage_generator = MultiStageGenerator(self.chat_system, self.config)
    
    def generate_complete_project(self, query: str, output_dir: str = None) -> Dict:
        """ç”Ÿæˆå®Œæ•´çš„AFSIMé¡¹ç›®"""
        self.logger.info(f"å¼€å§‹ç”Ÿæˆå®Œæ•´é¡¹ç›®: {query[:100]}...")
        
        # ä½¿ç”¨å¤šé˜¶æ®µç”Ÿæˆå™¨
        result = self.multi_stage_generator.generate_project(query, output_dir)
        
        # è®°å½•åˆ°å¯¹è¯å†å²
        self.chat_system.conversation_history.append({
            'query': query,
            'type': 'project_generation',
            'result': result,
            'timestamp': time.time()
        })
        
        return result
    
    def get_project_info(self):
        """è·å–é¡¹ç›®ä¿¡æ¯"""
        return self.chat_system.get_project_info()
    
    def get_vector_db_info(self):
        """è·å–å‘é‡æ•°æ®åº“ä¿¡æ¯"""
        return self.chat_system.get_vector_db_info()